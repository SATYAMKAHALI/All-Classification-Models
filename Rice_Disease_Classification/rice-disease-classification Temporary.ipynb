{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":796736,"sourceType":"datasetVersion","datasetId":193945}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import kagglehub\n\n# Download latest version\npath = kagglehub.dataset_download(\"minhhuy2810/rice-diseases-image-dataset\")\n\nprint(\"Path to dataset files:\", path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T09:59:32.531683Z","iopub.execute_input":"2025-01-12T09:59:32.531988Z","iopub.status.idle":"2025-01-12T09:59:33.152779Z","shell.execute_reply.started":"2025-01-12T09:59:32.531961Z","shell.execute_reply":"2025-01-12T09:59:33.152147Z"}},"outputs":[{"name":"stdout","text":"Path to dataset files: /kaggle/input/rice-diseases-image-dataset\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T09:59:35.650089Z","iopub.execute_input":"2025-01-12T09:59:35.650376Z","iopub.status.idle":"2025-01-12T09:59:39.998766Z","shell.execute_reply.started":"2025-01-12T09:59:35.650352Z","shell.execute_reply":"2025-01-12T09:59:39.997749Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.5)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import numpy as np \nimport matplotlib.pyplot as plt\nimport torch\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets,transforms\nfrom torchvision import models\nimport torch.optim as optim\nimport torch.nn as nn\nfrom tqdm import tqdm\nfrom sklearn.metrics import precision_score, recall_score, accuracy_score , f1_score , confusion_matrix\nfrom sklearn.preprocessing import StandardScaler ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T09:59:40.975760Z","iopub.execute_input":"2025-01-12T09:59:40.976082Z","iopub.status.idle":"2025-01-12T09:59:45.482244Z","shell.execute_reply.started":"2025-01-12T09:59:40.976054Z","shell.execute_reply":"2025-01-12T09:59:45.481379Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"device= torch.device ( 'cuda' if torch.cuda.is_available() else 'cpu' )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T09:59:47.542993Z","iopub.execute_input":"2025-01-12T09:59:47.543427Z","iopub.status.idle":"2025-01-12T09:59:47.590110Z","shell.execute_reply.started":"2025-01-12T09:59:47.543399Z","shell.execute_reply":"2025-01-12T09:59:47.589291Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"train_transforms= transforms.Compose([\n    transforms.Resize((224,224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.5,0.5,0.5],std=[0.5,0.5,0.5]),   \n])\nval_transforms = transforms.Compose([\n    transforms.Resize((224,224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.5,0.5,0.5],std=[0.5,0.5,0.5])\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T10:00:15.026578Z","iopub.execute_input":"2025-01-12T10:00:15.026884Z","iopub.status.idle":"2025-01-12T10:00:15.031771Z","shell.execute_reply.started":"2025-01-12T10:00:15.026861Z","shell.execute_reply":"2025-01-12T10:00:15.030919Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"import os\nbase_dir = '/kaggle/input/rice-diseases-image-dataset/RiceDiseaseDataset'\ntrain_dir = '/kaggle/input/rice-diseases-image-dataset/RiceDiseaseDataset/train'\nval_dir = '/kaggle/input/rice-diseases-image-dataset/RiceDiseaseDataset/validation'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T10:00:18.743227Z","iopub.execute_input":"2025-01-12T10:00:18.743543Z","iopub.status.idle":"2025-01-12T10:00:18.747285Z","shell.execute_reply.started":"2025-01-12T10:00:18.743516Z","shell.execute_reply":"2025-01-12T10:00:18.746414Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"from torchvision.datasets import ImageFolder\ntrain_data = ImageFolder(root=train_dir, transform = train_transforms) \nval_data = ImageFolder( root = val_dir, transform = val_transforms)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T10:00:21.495228Z","iopub.execute_input":"2025-01-12T10:00:21.495542Z","iopub.status.idle":"2025-01-12T10:00:28.314777Z","shell.execute_reply.started":"2025-01-12T10:00:21.495514Z","shell.execute_reply":"2025-01-12T10:00:28.314115Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"from torch.utils.data import DataLoader\ntrain_loader = DataLoader(train_data, batch_size = 32 , shuffle = True)\nval_loader = DataLoader(val_data, batch_size =32, shuffle = True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T10:00:31.127714Z","iopub.execute_input":"2025-01-12T10:00:31.128044Z","iopub.status.idle":"2025-01-12T10:00:31.132303Z","shell.execute_reply.started":"2025-01-12T10:00:31.128015Z","shell.execute_reply":"2025-01-12T10:00:31.131298Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"from torchsummary import summary\nimport torch.nn.functional as F\nclass CNNModelforRiceDisease(nn.Module):\n    def __init__(self,num_classes=4):\n        super(CNNModelforRiceDisease , self).__init__()\n        self.conv1 = nn.Conv2d(in_channels=3, out_channels = 32 , kernel_size = 3 , padding = 1 )\n        self.conv2 = nn.Conv2d(in_channels=32, out_channels = 64 , kernel_size =3, padding = 1)\n        self.conv3 = nn.Conv2d(in_channels=64 , out_channels=128, kernel_size= 3 , padding = 1)\n        self.conv4 = nn.Conv2d(in_channels=128, out_channels = 256, kernel_size=3, padding=1)\n        self.conv5 = nn.Conv2d(in_channels=256, out_channels=512 , kernel_size=3 , padding=1)\n        self.conv6 = nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=3 , padding= 1)\n        self.pool = nn.MaxPool2d(kernel_size=2 , stride = 2)\n        #Fully Connected Layer\n        self.fc1= nn.Linear(1024*3*3, 256)\n        self.fc2 = nn. Linear(256, 256)\n        self.fc3 = nn. Linear(256, num_classes)\n\n    def forward(self,input_image):\n        #Forward pass through convolutional Layers\n        input_image=F.leaky_relu(self.conv1(input_image), negative_slope=0.01)\n        input_image = self.pool(input_image)\n        input_image = F. leaky_relu(self.conv2(input_image), negative_slope=0.01)\n        input_image = self.pool(input_image)\n        input_image = F. leaky_relu(self.conv3(input_image), negative_slope = 0.01)\n        input_image = self.pool(input_image)\n        input_image = F. leaky_relu(self.conv4(input_image), negative_slope = 0.01)\n        input_image = self.pool(input_image)\n        input_image = F. leaky_relu(self.conv5(input_image), negative_slope = 0.01)\n        input_image = self.pool(input_image)\n        input_image = F. leaky_relu(self.conv6(input_image), negative_slope = 0.01)\n        input_image = self.pool(input_image)\n\n        #Flatten for fully connected layers\n        input_image = input_image.view(input_image.size(0), -1)\n\n        #Fully Connectedd layers\n        input_image = F.leaky_relu(self.fc1(input_image) , negative_slope = 0.01 )\n        input_image = F. leaky_relu(self.fc2(input_image), negative_slope= 0.01)\n        input_image = self.fc3(input_image)\n\n        return input_image\n  \n#Move the model to GPU if available\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = CNNModelforRiceDisease(num_classes=4).to(device)\n\n#Example to test the movement of tensor to device and check for proper connection with the forward layers\ninput_tensor = torch.randn(1*3*224*224).to(device)\n\n#summarize the model\nsummary(model,input_size=(3,224,224))  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T10:00:33.837764Z","iopub.execute_input":"2025-01-12T10:00:33.838057Z","iopub.status.idle":"2025-01-12T10:00:34.707568Z","shell.execute_reply.started":"2025-01-12T10:00:33.838035Z","shell.execute_reply":"2025-01-12T10:00:34.706685Z"}},"outputs":[{"name":"stdout","text":"----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Conv2d-1         [-1, 32, 224, 224]             896\n         MaxPool2d-2         [-1, 32, 112, 112]               0\n            Conv2d-3         [-1, 64, 112, 112]          18,496\n         MaxPool2d-4           [-1, 64, 56, 56]               0\n            Conv2d-5          [-1, 128, 56, 56]          73,856\n         MaxPool2d-6          [-1, 128, 28, 28]               0\n            Conv2d-7          [-1, 256, 28, 28]         295,168\n         MaxPool2d-8          [-1, 256, 14, 14]               0\n            Conv2d-9          [-1, 512, 14, 14]       1,180,160\n        MaxPool2d-10            [-1, 512, 7, 7]               0\n           Conv2d-11           [-1, 1024, 7, 7]       4,719,616\n        MaxPool2d-12           [-1, 1024, 3, 3]               0\n           Linear-13                  [-1, 256]       2,359,552\n           Linear-14                  [-1, 256]          65,792\n           Linear-15                    [-1, 4]           1,028\n================================================================\nTotal params: 8,714,564\nTrainable params: 8,714,564\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.57\nForward/backward pass size (MB): 30.13\nParams size (MB): 33.24\nEstimated Total Size (MB): 63.94\n----------------------------------------------------------------\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"#Hyperparameters\nbatch_size=32\nlearning_rate=0.01\nnum_epochs=20","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T10:00:40.559715Z","iopub.execute_input":"2025-01-12T10:00:40.559996Z","iopub.status.idle":"2025-01-12T10:00:40.563714Z","shell.execute_reply.started":"2025-01-12T10:00:40.559976Z","shell.execute_reply":"2025-01-12T10:00:40.562923Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"#defining loss functions and optimizers\nmodel= CNNModelforRiceDisease(num_classes=4).to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr= learning_rate)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T10:00:42.928032Z","iopub.execute_input":"2025-01-12T10:00:42.928333Z","iopub.status.idle":"2025-01-12T10:00:43.015621Z","shell.execute_reply.started":"2025-01-12T10:00:42.928312Z","shell.execute_reply":"2025-01-12T10:00:43.014967Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"def train_model(model, train_loader, val_loader , num_epochs=num_epochs, learning_rate=learning_rate):\n    train_loss,val_loss=[],[]\n    train_accuracy,val_accuracy=[0],[0]\n    precision_scores,recall_scores,f1_scores=[],[],[]\n    #DEFINE OPTIMIZER & CRITERION\n    optimizer = optimizer\n    criterion = criterion\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T10:00:45.114331Z","iopub.execute_input":"2025-01-12T10:00:45.114699Z","iopub.status.idle":"2025-01-12T10:00:45.118822Z","shell.execute_reply.started":"2025-01-12T10:00:45.114670Z","shell.execute_reply":"2025-01-12T10:00:45.117935Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"from tqdm import tqdm\n#Initialize metrics\ntrain_loss,val_loss=[],[]\ntrain_accuracy,val_accuracy=[0],[0]\nprecision_scores,recall_scores,f1_scores=[],[],[]\n#Training Loop\nfor epoch in range(num_epochs):\n    model.train()\n    epoch_loss,total_train,correct_train = 0.0, 0, 0\n    loop = tqdm(train_loader, total= len(train_loader), leave=False)\n    for inputs, labels in loop:\n        inputs = inputs.to(device)\n        labels=labels.to(device)\n        #Zero gradients\n        optimizer.zero_grad()\n        #Forward pass\n        output=model(inputs)\n        loss=criterion(output,labels)\n        #Backward pass and optimization\n        loss.backward()\n        optimizer.step()\n        #update metrics\n        epoch_loss = epoch_loss + loss.item()\n        _, predicted = torch.max(output, 1)\n        correct_train += (predicted==labels).sum().item()\n        total_train += labels.size(0)\n        #put tqdm description\n        loop.set_description(f\"Epoch[{epoch+1}/{num_epochs}]\")\n        loop.set_postfix(loss=loss.item())\n\n    #Training Statistiics\n    train_loss.append(epoch_loss/len(train_loader))\n    train_accuracy.append(100*correct_train/total_train)\n    #Validation loop\n    model.eval()\n    val_epoch_loss = 0.0\n    correct_val,total_val=0,0\n    all_labels,all_preds = [],[]\n\n    with torch.no_grad():\n        for inputs,labels in val_loader:\n            inputs,labels = inputs.to(device),labels.to(device)\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            val_epoch_loss += loss.item()\n            _,predicted = torch.max(outputs,1)\n            correct_val += (predicted==labels).sum().item()\n            total_val+=labels.size(0)\n            all_labels.extend(labels.cpu().numpy())\n            all_preds.extend(predicted.cpu().numpy())\n    #Validation metrics\n    val_loss.append(val_epoch_loss/ len(val_loader))\n    val_accuracy.append(100* correct_val/total_val)\n    precision_scores.append(precision_score(all_labels,all_preds,average='weighted', zero_division=0))\n    recall_scores.append(recall_score(all_labels,all_preds,average='weighted', zero_division=0))\n    f1_scores.append(f1_score(all_labels,all_preds,average='weighted', zero_division=0))\n\n    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss[-1]:.4f}, Val Loss:{val_loss[-1]:.4f}, Val Accuracy:{val_accuracy[-1]:.2f}% \")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-12T10:09:10.176502Z","iopub.execute_input":"2025-01-12T10:09:10.176847Z","iopub.status.idle":"2025-01-12T11:03:32.163468Z","shell.execute_reply.started":"2025-01-12T10:09:10.176821Z","shell.execute_reply":"2025-01-12T11:03:32.162710Z"}},"outputs":[{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 1/20, Train Loss: 5793707.3587, Val Loss:5192224.7031, Val Accuracy:25.00% \n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 2/20, Train Loss: 9723401.0659, Val Loss:545218.8457, Val Accuracy:24.80% \n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 3/20, Train Loss: 977361.1366, Val Loss:377799.3047, Val Accuracy:25.00% \n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 4/20, Train Loss: 232536.0484, Val Loss:356790.0410, Val Accuracy:25.00% \n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 5/20, Train Loss: 143755.0347, Val Loss:49311.6299, Val Accuracy:25.81% \n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 6/20, Train Loss: 25466.1149, Val Loss:17193.2215, Val Accuracy:27.44% \n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 7/20, Train Loss: 18435.1075, Val Loss:8707.4236, Val Accuracy:32.52% \n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 8/20, Train Loss: 11825.7241, Val Loss:10833.6515, Val Accuracy:28.46% \n","output_type":"stream"},{"name":"stderr","text":"                                                                          \r","output_type":"stream"},{"name":"stdout","text":"Epoch 9/20, Train Loss: 11527.2553, Val Loss:6350.4560, Val Accuracy:25.00% \n","output_type":"stream"},{"name":"stderr","text":"                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 10/20, Train Loss: 5841.2565, Val Loss:6286.7241, Val Accuracy:29.07% \n","output_type":"stream"},{"name":"stderr","text":"                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 11/20, Train Loss: 6516.8224, Val Loss:8609.6602, Val Accuracy:24.59% \n","output_type":"stream"},{"name":"stderr","text":"                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 12/20, Train Loss: 5641.6480, Val Loss:10593.3864, Val Accuracy:27.24% \n","output_type":"stream"},{"name":"stderr","text":"                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 13/20, Train Loss: 4837.2243, Val Loss:4422.4157, Val Accuracy:30.89% \n","output_type":"stream"},{"name":"stderr","text":"                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 14/20, Train Loss: 16832.9032, Val Loss:15930.4344, Val Accuracy:25.00% \n","output_type":"stream"},{"name":"stderr","text":"                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 15/20, Train Loss: 32077.1519, Val Loss:13400.4152, Val Accuracy:31.71% \n","output_type":"stream"},{"name":"stderr","text":"                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 16/20, Train Loss: 19924.4491, Val Loss:20233.4999, Val Accuracy:25.00% \n","output_type":"stream"},{"name":"stderr","text":"                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 17/20, Train Loss: 7081.1512, Val Loss:3646.7214, Val Accuracy:21.95% \n","output_type":"stream"},{"name":"stderr","text":"                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 18/20, Train Loss: 4086.5503, Val Loss:3979.2845, Val Accuracy:29.67% \n","output_type":"stream"},{"name":"stderr","text":"                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 19/20, Train Loss: 3790.5749, Val Loss:2265.4185, Val Accuracy:23.58% \n","output_type":"stream"},{"name":"stderr","text":"                                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 20/20, Train Loss: 3449.2874, Val Loss:3881.2581, Val Accuracy:27.44% \n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}